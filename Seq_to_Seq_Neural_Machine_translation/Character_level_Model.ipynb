{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X41hGaRU-Ibr"
   },
   "source": [
    "#### Name: MansiMrugen Shah\n",
    "#### NetID: ws2865"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTXZegw7-Ibs"
   },
   "source": [
    "### Build a character-level model Seq2Seq Language Translation model for any language pair of your choice.\n",
    "\n",
    "In English, all words are formed by 26 (or 52 if including both upper and lower case character, or even more if including special characters). Having the character embedding, every single word’s vector can be formed even for words not in the vocabulary. On the other hand, word embedding can only handle the words that have been seen.\n",
    "Character embedding fits better for misspelt words and new words.\n",
    "\n",
    "It handles infrequent words better than word embedding as the latter suffers from lack of enough training opportunity on those rare words.\n",
    "Another benefit is that as the vector is smaller compared to word embedding, it reduces model complexity and improves the performance (in terms of speed).\n",
    "\n",
    "### English to Marathi language translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNqm9CPc0Wzt"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from __future__ import print_function\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from string import digits\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNEtv7f7-Ibw"
   },
   "source": [
    "### Load the dataset and set other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekz-msRS10ya"
   },
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "epochs = 120 \n",
    "latent_dim = 256 \n",
    "num_samples = 38000 \n",
    "data_path = '/content/mar.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP-m4zy0-Ibz"
   },
   "source": [
    "### Clean the data by removing punctuations, digits and convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3i1ZdF6b2KgL"
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "Eng_texts = []\n",
    "Mar_texts = []\n",
    "Eng_characters = set()\n",
    "Mar_characters = set()\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    Eng_text, Mar_text, _ = line.split('\\t')\n",
    "    Eng_text = Eng_text.lower()\n",
    "    Mar_text = Mar_text.lower()\n",
    "    Eng_text = re.sub(\"'\", '', Eng_text)\n",
    "    Eng_text = re.sub(\",\", ' COMMA', Eng_text)\n",
    "    Mar_text = re.sub(\"'\", '', Mar_text)\n",
    "    Mar_text = re.sub(\",\", ' COMMA', Mar_text)\n",
    "    Eng_text = ''.join(x for x in Eng_text if x not in exclude)\n",
    "    Mar_text = ''.join(x for x in Mar_text if x not in exclude)\n",
    "    Eng_text = Eng_text.translate(remove_digits)\n",
    "    Mar_text = Mar_text.translate(remove_digits)\n",
    "    Mar_text = '\\t' + Mar_text + '\\n'\n",
    "    Eng_texts.append(Eng_text)\n",
    "    Mar_texts.append(Mar_text)\n",
    "    for char in Eng_text:\n",
    "        if char not in Eng_characters:\n",
    "            Eng_characters.add(char)\n",
    "    for char in Mar_text:\n",
    "        if char not in Mar_characters:\n",
    "            Mar_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "F9C9vBp22L43",
    "outputId": "6cb3659a-270f-4d7c-cf38-ac4562f84a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 38000\n",
      "Number of unique input tokens: 37\n",
      "Number of unique output tokens: 98\n",
      "Max sequence length for inputs: 61\n",
      "Max sequence length for outputs: 85\n"
     ]
    }
   ],
   "source": [
    "Eng_characters = sorted(list(Eng_characters))\n",
    "Mar_characters = sorted(list(Mar_characters))\n",
    "num_encoder_tokens = len(Eng_characters)\n",
    "num_decoder_tokens = len(Mar_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in Eng_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in Mar_texts])\n",
    "\n",
    "print('Number of samples:', len(Eng_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GURqdyN-Ib4"
   },
   "source": [
    "### Create a dictionary for english and marathi characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vhhbCGF2RSh"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(Eng_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(Mar_characters)])\n",
    "\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(Eng_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(Eng_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(Eng_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_cJbBvE-Ib6"
   },
   "source": [
    "###  One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idEp8rZL2X4O"
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, (Eng_text, Mar_text) in enumerate(zip(Eng_texts, Mar_texts)):\n",
    "    for t, char in enumerate(Eng_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(Mar_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_fFAalG4pMC"
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eK5TnafZ2a3Y"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True, dropout = 0.3)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJPVT2Sf-Ib_"
   },
   "source": [
    "### Compile and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TLdeNIlZ2gVj",
    "outputId": "8da86a7f-13c7-484e-ca73-31a1ab80a274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "535/535 [==============================] - 13s 24ms/step - loss: 0.8608 - accuracy: 0.7885 - val_loss: 1.1972 - val_accuracy: 0.6804\n",
      "Epoch 2/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.6396 - accuracy: 0.8256 - val_loss: 1.0636 - val_accuracy: 0.7116\n",
      "Epoch 3/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.5853 - accuracy: 0.8385 - val_loss: 0.9962 - val_accuracy: 0.7299\n",
      "Epoch 4/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.5500 - accuracy: 0.8469 - val_loss: 0.9375 - val_accuracy: 0.7447\n",
      "Epoch 5/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.5251 - accuracy: 0.8529 - val_loss: 0.8750 - val_accuracy: 0.7602\n",
      "Epoch 6/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.5060 - accuracy: 0.8576 - val_loss: 0.8436 - val_accuracy: 0.7677\n",
      "Epoch 7/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4911 - accuracy: 0.8613 - val_loss: 0.8231 - val_accuracy: 0.7731\n",
      "Epoch 8/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4784 - accuracy: 0.8645 - val_loss: 0.8097 - val_accuracy: 0.7772\n",
      "Epoch 9/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4687 - accuracy: 0.8669 - val_loss: 0.7964 - val_accuracy: 0.7803\n",
      "Epoch 10/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4592 - accuracy: 0.8694 - val_loss: 0.7727 - val_accuracy: 0.7866\n",
      "Epoch 11/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4504 - accuracy: 0.8717 - val_loss: 0.7568 - val_accuracy: 0.7901\n",
      "Epoch 12/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4428 - accuracy: 0.8739 - val_loss: 0.7555 - val_accuracy: 0.7911\n",
      "Epoch 13/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4348 - accuracy: 0.8761 - val_loss: 0.7401 - val_accuracy: 0.7944\n",
      "Epoch 14/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4296 - accuracy: 0.8774 - val_loss: 0.7308 - val_accuracy: 0.7970\n",
      "Epoch 15/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4241 - accuracy: 0.8790 - val_loss: 0.7241 - val_accuracy: 0.7990\n",
      "Epoch 16/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4197 - accuracy: 0.8800 - val_loss: 0.7282 - val_accuracy: 0.7980\n",
      "Epoch 17/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4142 - accuracy: 0.8815 - val_loss: 0.7152 - val_accuracy: 0.8004\n",
      "Epoch 18/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4108 - accuracy: 0.8824 - val_loss: 0.7196 - val_accuracy: 0.8004\n",
      "Epoch 19/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4065 - accuracy: 0.8837 - val_loss: 0.7065 - val_accuracy: 0.8034\n",
      "Epoch 20/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.4030 - accuracy: 0.8846 - val_loss: 0.7050 - val_accuracy: 0.8034\n",
      "Epoch 21/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3992 - accuracy: 0.8856 - val_loss: 0.7005 - val_accuracy: 0.8054\n",
      "Epoch 22/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3956 - accuracy: 0.8865 - val_loss: 0.6925 - val_accuracy: 0.8072\n",
      "Epoch 23/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3926 - accuracy: 0.8873 - val_loss: 0.6956 - val_accuracy: 0.8068\n",
      "Epoch 24/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3894 - accuracy: 0.8882 - val_loss: 0.6870 - val_accuracy: 0.8079\n",
      "Epoch 25/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3860 - accuracy: 0.8892 - val_loss: 0.6848 - val_accuracy: 0.8088\n",
      "Epoch 26/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3835 - accuracy: 0.8898 - val_loss: 0.6870 - val_accuracy: 0.8090\n",
      "Epoch 27/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3811 - accuracy: 0.8908 - val_loss: 0.6784 - val_accuracy: 0.8102\n",
      "Epoch 28/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3789 - accuracy: 0.8911 - val_loss: 0.6827 - val_accuracy: 0.8098\n",
      "Epoch 29/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3760 - accuracy: 0.8919 - val_loss: 0.6835 - val_accuracy: 0.8097\n",
      "Epoch 30/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3732 - accuracy: 0.8927 - val_loss: 0.6727 - val_accuracy: 0.8123\n",
      "Epoch 31/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3721 - accuracy: 0.8930 - val_loss: 0.6771 - val_accuracy: 0.8115\n",
      "Epoch 32/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.3696 - accuracy: 0.8936 - val_loss: 0.6694 - val_accuracy: 0.8130\n",
      "Epoch 33/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3675 - accuracy: 0.8941 - val_loss: 0.6747 - val_accuracy: 0.8120\n",
      "Epoch 34/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3651 - accuracy: 0.8950 - val_loss: 0.6682 - val_accuracy: 0.8139\n",
      "Epoch 35/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.3625 - accuracy: 0.8955 - val_loss: 0.6747 - val_accuracy: 0.8122\n",
      "Epoch 36/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3619 - accuracy: 0.8958 - val_loss: 0.6649 - val_accuracy: 0.8148\n",
      "Epoch 37/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.3595 - accuracy: 0.8964 - val_loss: 0.6633 - val_accuracy: 0.8156\n",
      "Epoch 38/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.3576 - accuracy: 0.8970 - val_loss: 0.6655 - val_accuracy: 0.8147\n",
      "Epoch 39/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3554 - accuracy: 0.8977 - val_loss: 0.6602 - val_accuracy: 0.8163\n",
      "Epoch 40/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3541 - accuracy: 0.8981 - val_loss: 0.6642 - val_accuracy: 0.8156\n",
      "Epoch 41/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3534 - accuracy: 0.8982 - val_loss: 0.6563 - val_accuracy: 0.8170\n",
      "Epoch 42/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3511 - accuracy: 0.8989 - val_loss: 0.6593 - val_accuracy: 0.8161\n",
      "Epoch 43/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3490 - accuracy: 0.8994 - val_loss: 0.6615 - val_accuracy: 0.8164\n",
      "Epoch 44/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3476 - accuracy: 0.8998 - val_loss: 0.6669 - val_accuracy: 0.8167\n",
      "Epoch 45/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3461 - accuracy: 0.9003 - val_loss: 0.6537 - val_accuracy: 0.8181\n",
      "Epoch 46/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3446 - accuracy: 0.9006 - val_loss: 0.6523 - val_accuracy: 0.8186\n",
      "Epoch 47/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3428 - accuracy: 0.9010 - val_loss: 0.6490 - val_accuracy: 0.8187\n",
      "Epoch 48/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3420 - accuracy: 0.9014 - val_loss: 0.6540 - val_accuracy: 0.8180\n",
      "Epoch 49/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3407 - accuracy: 0.9017 - val_loss: 0.6516 - val_accuracy: 0.8187\n",
      "Epoch 50/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3390 - accuracy: 0.9020 - val_loss: 0.6480 - val_accuracy: 0.8200\n",
      "Epoch 51/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3371 - accuracy: 0.9027 - val_loss: 0.6462 - val_accuracy: 0.8203\n",
      "Epoch 52/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3364 - accuracy: 0.9029 - val_loss: 0.6493 - val_accuracy: 0.8199\n",
      "Epoch 53/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3351 - accuracy: 0.9033 - val_loss: 0.6486 - val_accuracy: 0.8196\n",
      "Epoch 54/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3350 - accuracy: 0.9033 - val_loss: 0.6527 - val_accuracy: 0.8197\n",
      "Epoch 55/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3331 - accuracy: 0.9038 - val_loss: 0.6483 - val_accuracy: 0.8203\n",
      "Epoch 56/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3308 - accuracy: 0.9044 - val_loss: 0.6528 - val_accuracy: 0.8201\n",
      "Epoch 57/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3301 - accuracy: 0.9047 - val_loss: 0.6466 - val_accuracy: 0.8214\n",
      "Epoch 58/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3286 - accuracy: 0.9051 - val_loss: 0.6494 - val_accuracy: 0.8211\n",
      "Epoch 59/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3272 - accuracy: 0.9054 - val_loss: 0.6499 - val_accuracy: 0.8207\n",
      "Epoch 60/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3263 - accuracy: 0.9057 - val_loss: 0.6527 - val_accuracy: 0.8203\n",
      "Epoch 61/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3245 - accuracy: 0.9062 - val_loss: 0.6460 - val_accuracy: 0.8217\n",
      "Epoch 62/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3230 - accuracy: 0.9066 - val_loss: 0.6437 - val_accuracy: 0.8225\n",
      "Epoch 63/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3235 - accuracy: 0.9065 - val_loss: 0.6457 - val_accuracy: 0.8224\n",
      "Epoch 64/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3221 - accuracy: 0.9068 - val_loss: 0.6477 - val_accuracy: 0.8213\n",
      "Epoch 65/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3214 - accuracy: 0.9070 - val_loss: 0.6452 - val_accuracy: 0.8222\n",
      "Epoch 66/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3203 - accuracy: 0.9073 - val_loss: 0.6465 - val_accuracy: 0.8221\n",
      "Epoch 67/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3194 - accuracy: 0.9076 - val_loss: 0.6446 - val_accuracy: 0.8215\n",
      "Epoch 68/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3181 - accuracy: 0.9080 - val_loss: 0.6499 - val_accuracy: 0.8217\n",
      "Epoch 69/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3171 - accuracy: 0.9083 - val_loss: 0.6435 - val_accuracy: 0.8227\n",
      "Epoch 70/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3159 - accuracy: 0.9085 - val_loss: 0.6450 - val_accuracy: 0.8216\n",
      "Epoch 71/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3159 - accuracy: 0.9085 - val_loss: 0.6415 - val_accuracy: 0.8230\n",
      "Epoch 72/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3152 - accuracy: 0.9088 - val_loss: 0.6413 - val_accuracy: 0.8231\n",
      "Epoch 73/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3138 - accuracy: 0.9092 - val_loss: 0.6459 - val_accuracy: 0.8222\n",
      "Epoch 74/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3118 - accuracy: 0.9096 - val_loss: 0.6446 - val_accuracy: 0.8227\n",
      "Epoch 75/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3121 - accuracy: 0.9096 - val_loss: 0.6475 - val_accuracy: 0.8222\n",
      "Epoch 76/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3116 - accuracy: 0.9097 - val_loss: 0.6517 - val_accuracy: 0.8212\n",
      "Epoch 77/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3104 - accuracy: 0.9100 - val_loss: 0.6450 - val_accuracy: 0.8228\n",
      "Epoch 78/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3096 - accuracy: 0.9103 - val_loss: 0.6435 - val_accuracy: 0.8231\n",
      "Epoch 79/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3088 - accuracy: 0.9105 - val_loss: 0.6434 - val_accuracy: 0.8235\n",
      "Epoch 80/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3084 - accuracy: 0.9106 - val_loss: 0.6430 - val_accuracy: 0.8233\n",
      "Epoch 81/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3074 - accuracy: 0.9110 - val_loss: 0.6437 - val_accuracy: 0.8239\n",
      "Epoch 82/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3067 - accuracy: 0.9112 - val_loss: 0.6437 - val_accuracy: 0.8239\n",
      "Epoch 83/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3052 - accuracy: 0.9116 - val_loss: 0.6452 - val_accuracy: 0.8237\n",
      "Epoch 84/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3050 - accuracy: 0.9115 - val_loss: 0.6414 - val_accuracy: 0.8239\n",
      "Epoch 85/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3046 - accuracy: 0.9118 - val_loss: 0.6370 - val_accuracy: 0.8254\n",
      "Epoch 86/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3030 - accuracy: 0.9122 - val_loss: 0.6435 - val_accuracy: 0.8230\n",
      "Epoch 87/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3023 - accuracy: 0.9124 - val_loss: 0.6465 - val_accuracy: 0.8234\n",
      "Epoch 88/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3023 - accuracy: 0.9124 - val_loss: 0.6503 - val_accuracy: 0.8226\n",
      "Epoch 89/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3011 - accuracy: 0.9128 - val_loss: 0.6392 - val_accuracy: 0.8240\n",
      "Epoch 90/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.3011 - accuracy: 0.9126 - val_loss: 0.6462 - val_accuracy: 0.8234\n",
      "Epoch 91/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.2993 - accuracy: 0.9132 - val_loss: 0.6388 - val_accuracy: 0.8243\n",
      "Epoch 92/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.2998 - accuracy: 0.9130 - val_loss: 0.6478 - val_accuracy: 0.8235\n",
      "Epoch 93/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.2985 - accuracy: 0.9133 - val_loss: 0.6396 - val_accuracy: 0.8247\n",
      "Epoch 94/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.2986 - accuracy: 0.9133 - val_loss: 0.6462 - val_accuracy: 0.8242\n",
      "Epoch 95/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.2970 - accuracy: 0.9138 - val_loss: 0.6390 - val_accuracy: 0.8249\n",
      "Epoch 96/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2957 - accuracy: 0.9142 - val_loss: 0.6376 - val_accuracy: 0.8251\n",
      "Epoch 97/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2953 - accuracy: 0.9142 - val_loss: 0.6492 - val_accuracy: 0.8231\n",
      "Epoch 98/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2957 - accuracy: 0.9141 - val_loss: 0.6486 - val_accuracy: 0.8233\n",
      "Epoch 99/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2949 - accuracy: 0.9143 - val_loss: 0.6398 - val_accuracy: 0.8243\n",
      "Epoch 100/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2940 - accuracy: 0.9146 - val_loss: 0.6417 - val_accuracy: 0.8243\n",
      "Epoch 101/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2936 - accuracy: 0.9148 - val_loss: 0.6464 - val_accuracy: 0.8237\n",
      "Epoch 102/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2933 - accuracy: 0.9146 - val_loss: 0.6398 - val_accuracy: 0.8249\n",
      "Epoch 103/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2930 - accuracy: 0.9147 - val_loss: 0.6435 - val_accuracy: 0.8241\n",
      "Epoch 104/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2913 - accuracy: 0.9152 - val_loss: 0.6396 - val_accuracy: 0.8252\n",
      "Epoch 105/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2911 - accuracy: 0.9155 - val_loss: 0.6381 - val_accuracy: 0.8251\n",
      "Epoch 106/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2901 - accuracy: 0.9156 - val_loss: 0.6415 - val_accuracy: 0.8247\n",
      "Epoch 107/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2902 - accuracy: 0.9156 - val_loss: 0.6485 - val_accuracy: 0.8242\n",
      "Epoch 108/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2892 - accuracy: 0.9159 - val_loss: 0.6401 - val_accuracy: 0.8249\n",
      "Epoch 109/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2898 - accuracy: 0.9157 - val_loss: 0.6367 - val_accuracy: 0.8263\n",
      "Epoch 110/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2894 - accuracy: 0.9158 - val_loss: 0.6405 - val_accuracy: 0.8244\n",
      "Epoch 111/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2880 - accuracy: 0.9162 - val_loss: 0.6397 - val_accuracy: 0.8258\n",
      "Epoch 112/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2874 - accuracy: 0.9164 - val_loss: 0.6491 - val_accuracy: 0.8244\n",
      "Epoch 113/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2869 - accuracy: 0.9164 - val_loss: 0.6461 - val_accuracy: 0.8243\n",
      "Epoch 114/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2869 - accuracy: 0.9165 - val_loss: 0.6496 - val_accuracy: 0.8241\n",
      "Epoch 115/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2860 - accuracy: 0.9168 - val_loss: 0.6434 - val_accuracy: 0.8241\n",
      "Epoch 116/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2853 - accuracy: 0.9169 - val_loss: 0.6412 - val_accuracy: 0.8251\n",
      "Epoch 117/120\n",
      "535/535 [==============================] - 12s 23ms/step - loss: 0.2848 - accuracy: 0.9170 - val_loss: 0.6406 - val_accuracy: 0.8249\n",
      "Epoch 118/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.2845 - accuracy: 0.9172 - val_loss: 0.6417 - val_accuracy: 0.8246\n",
      "Epoch 119/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.2839 - accuracy: 0.9174 - val_loss: 0.6422 - val_accuracy: 0.8246\n",
      "Epoch 120/120\n",
      "535/535 [==============================] - 12s 22ms/step - loss: 0.2837 - accuracy: 0.9173 - val_loss: 0.6483 - val_accuracy: 0.8240\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PwtXL6Bh-IcE"
   },
   "source": [
    "### Maximum validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2uFvaGJt-IcF",
    "outputId": "78137900-e562-406e-fa20-0eefc57ceeca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy of validation:  0.8262848258018494\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum accuracy of validation: \", max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ywz_AVFx2jF4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t8Cvx3KT-IcJ"
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WacWDTRy2o_A"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WemJmzU-IcL"
   },
   "source": [
    "### Inference Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gHw7GQVd2-kl",
    "outputId": "a3742494-6386-44ce-e5db-0478a5ef3697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: we won\n",
      "Actual sentence: \tआम्ही जिंकलो\n",
      "\n",
      "Decoded sentence: आपण हसलो\n",
      "\n",
      "-\n",
      "Input sentence: we won\n",
      "Actual sentence: \tआपण जिंकलो\n",
      "\n",
      "Decoded sentence: आपण हसलो\n",
      "\n",
      "-\n",
      "Input sentence: why me\n",
      "Actual sentence: \tमीच का\n",
      "\n",
      "Decoded sentence: मी का आले\n",
      "\n",
      "-\n",
      "Input sentence: why me\n",
      "Actual sentence: \tमी का\n",
      "\n",
      "Decoded sentence: मी का आले\n",
      "\n",
      "-\n",
      "Input sentence: ask tom\n",
      "Actual sentence: \tटॉमला विचार\n",
      "\n",
      "Decoded sentence: टॉमला बोलवा\n",
      "\n",
      "-\n",
      "Input sentence: ask tom\n",
      "Actual sentence: \tटॉमला विचारा\n",
      "\n",
      "Decoded sentence: टॉमला बोलवा\n",
      "\n",
      "-\n",
      "Input sentence: call me\n",
      "Actual sentence: \tमला बोलव\n",
      "\n",
      "Decoded sentence: मला बोलवा\n",
      "\n",
      "-\n",
      "Input sentence: call me\n",
      "Actual sentence: \tमला बोलवा\n",
      "\n",
      "Decoded sentence: मला बोलवा\n",
      "\n",
      "-\n",
      "Input sentence: call me\n",
      "Actual sentence: \tमला फोन करा\n",
      "\n",
      "Decoded sentence: मला बोलवा\n",
      "\n",
      "-\n",
      "Input sentence: call me\n",
      "Actual sentence: \tमला फोन कर\n",
      "\n",
      "Decoded sentence: मला बोलवा\n",
      "\n",
      "-\n",
      "Input sentence: call us\n",
      "Actual sentence: \tआम्हाला फोन कर\n",
      "\n",
      "Decoded sentence: आम्हाला बोलवा\n",
      "\n",
      "-\n",
      "Input sentence: call us\n",
      "Actual sentence: \tआम्हाला फोन करा\n",
      "\n",
      "Decoded sentence: आम्हाला बोलवा\n",
      "\n",
      "-\n",
      "Input sentence: come in\n",
      "Actual sentence: \tआत ये\n",
      "\n",
      "Decoded sentence: आत ये\n",
      "\n",
      "-\n",
      "Input sentence: fold it\n",
      "Actual sentence: \tघडी घाल\n",
      "\n",
      "Decoded sentence: उडी मार\n",
      "\n",
      "-\n",
      "Input sentence: fold it\n",
      "Actual sentence: \tघडी घाला\n",
      "\n",
      "Decoded sentence: उडी मार\n",
      "\n",
      "-\n",
      "Input sentence: get tom\n",
      "Actual sentence: \tटॉमला घे\n",
      "\n",
      "Decoded sentence: टॉमला विचारा\n",
      "\n",
      "-\n",
      "Input sentence: get tom\n",
      "Actual sentence: \tटॉमला आण\n",
      "\n",
      "Decoded sentence: टॉमला विचारा\n",
      "\n",
      "-\n",
      "Input sentence: get tom\n",
      "Actual sentence: \tटॉमला पकड\n",
      "\n",
      "Decoded sentence: टॉमला विचारा\n",
      "\n",
      "-\n",
      "Input sentence: get out\n",
      "Actual sentence: \tबाहेर हो\n",
      "\n",
      "Decoded sentence: सापडेल\n",
      "\n",
      "-\n",
      "Input sentence: get out\n",
      "Actual sentence: \tबाहेर व्हा\n",
      "\n",
      "Decoded sentence: सापडेल\n",
      "\n",
      "-\n",
      "Input sentence: go home\n",
      "Actual sentence: \tघरी जा\n",
      "\n",
      "Decoded sentence: घरी जाऊ                                                                               \n",
      "-\n",
      "Input sentence: he came\n",
      "Actual sentence: \tतो आला\n",
      "\n",
      "Decoded sentence: तो आला\n",
      "\n",
      "-\n",
      "Input sentence: he came\n",
      "Actual sentence: \tते आले\n",
      "\n",
      "Decoded sentence: तो आला\n",
      "\n",
      "-\n",
      "Input sentence: he runs\n",
      "Actual sentence: \tतो पळतो\n",
      "\n",
      "Decoded sentence: ते पळतात\n",
      "\n",
      "-\n",
      "Input sentence: he runs\n",
      "Actual sentence: \tते पळतात\n",
      "\n",
      "Decoded sentence: ते पळतात\n",
      "\n",
      "-\n",
      "Input sentence: he runs\n",
      "Actual sentence: \tतो धावतो\n",
      "\n",
      "Decoded sentence: ते पळतात\n",
      "\n",
      "-\n",
      "Input sentence: he runs\n",
      "Actual sentence: \tते धावतात\n",
      "\n",
      "Decoded sentence: ते पळतात\n",
      "\n",
      "-\n",
      "Input sentence: help me\n",
      "Actual sentence: \tवाचवा\n",
      "\n",
      "Decoded sentence: मला सांग\n",
      "\n",
      "-\n",
      "Input sentence: help me\n",
      "Actual sentence: \tवाचव\n",
      "\n",
      "Decoded sentence: मला सांग\n",
      "\n",
      "-\n",
      "Input sentence: help me\n",
      "Actual sentence: \tमाझी मदत करा\n",
      "\n",
      "Decoded sentence: मला सांग\n",
      "\n",
      "-\n",
      "Input sentence: help me\n",
      "Actual sentence: \tमला वाचव\n",
      "\n",
      "Decoded sentence: मला सांग\n",
      "\n",
      "-\n",
      "Input sentence: help me\n",
      "Actual sentence: \tमला वाचवा\n",
      "\n",
      "Decoded sentence: मला सांग\n",
      "\n",
      "-\n",
      "Input sentence: help us\n",
      "Actual sentence: \tआमची मदत करा\n",
      "\n",
      "Decoded sentence: आम्हाला बघा\n",
      "\n",
      "-\n",
      "Input sentence: help us\n",
      "Actual sentence: \tआमची मदत कर\n",
      "\n",
      "Decoded sentence: आम्हाला बघा\n",
      "\n",
      "-\n",
      "Input sentence: help us\n",
      "Actual sentence: \tआम्हाला वाचव\n",
      "\n",
      "Decoded sentence: आम्हाला बघा\n",
      "\n",
      "-\n",
      "Input sentence: im tom\n",
      "Actual sentence: \tमी टॉम\n",
      "\n",
      "Decoded sentence: मी टॉम\n",
      "\n",
      "-\n",
      "Input sentence: im tom\n",
      "Actual sentence: \tटॉम मीच\n",
      "\n",
      "Decoded sentence: मी टॉम\n",
      "\n",
      "-\n",
      "Input sentence: im tom\n",
      "Actual sentence: \tमी टॉम आहे\n",
      "\n",
      "Decoded sentence: मी टॉम\n",
      "\n",
      "-\n",
      "Input sentence: im fat\n",
      "Actual sentence: \tमी जाडा आहे\n",
      "\n",
      "Decoded sentence: मी प्रयत्न करतेय\n",
      "\n",
      "-\n",
      "Input sentence: im fat\n",
      "Actual sentence: \tमी जाडी आहे\n",
      "\n",
      "Decoded sentence: मी प्रयत्न करतेय\n",
      "\n",
      "-\n",
      "Input sentence: im ill\n",
      "Actual sentence: \tमी आजारी आहे\n",
      "\n",
      "Decoded sentence: मी पुन्हा आहे\n",
      "\n",
      "-\n",
      "Input sentence: its ok\n",
      "Actual sentence: \tठीक आहे\n",
      "\n",
      "Decoded sentence: ५० मांजर आहेत\n",
      "\n",
      "-\n",
      "Input sentence: its me\n",
      "Actual sentence: \tमी आहे\n",
      "\n",
      "Decoded sentence: माझं आहे\n",
      "\n",
      "-\n",
      "Input sentence: its me\n",
      "Actual sentence: \tमी आहे\n",
      "\n",
      "Decoded sentence: माझं आहे\n",
      "\n",
      "-\n",
      "Input sentence: me COMMA too\n",
      "Actual sentence: \tमी पण\n",
      "\n",
      "Decoded sentence: बरं COMMA थांब\n",
      "\n",
      "-\n",
      "Input sentence: me COMMA too\n",
      "Actual sentence: \tमला पण\n",
      "\n",
      "Decoded sentence: बरं COMMA थांब\n",
      "\n",
      "-\n",
      "Input sentence: open up\n",
      "Actual sentence: \tउघड\n",
      "\n",
      "Decoded sentence: उडी मार\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for seq_index in range(53,100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "\n",
    "    print('-')\n",
    "    print('Input sentence:', Eng_texts[seq_index])\n",
    "    print('Actual sentence:', Mar_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Character_Level_Shah_Mansi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
